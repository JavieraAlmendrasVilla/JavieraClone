import os

from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_groq import ChatGroq
import json
import gradio as gr

JAVIERA_PROFILE = os.environ.get("JAVIERA_PROFILE")
API_KEY = os.environ.get("API_KEY")
SYSTEM_PROMPT= os.environ.get("SYSTEM_PROMPT")

# Privacy restrictions remain the same
RESTRICTED_TOPICS = json.loads(os.environ["RESTRICTED_TOPICS"])


def check_privacy_restrictions(question: str) -> bool:
    """Check if question contains restricted topics."""
    question_lower = question.lower()
    return any(topic in question_lower for topic in RESTRICTED_TOPICS)


# Natural conversation prompt template
NATURAL_TEMPLATE = SYSTEM_PROMPT

# Initialize LLM with optimized parameters

llm = ChatGroq(
    model="llama-3.1-8b-instant",
    temperature=0.5,
    api_key=API_KEY

)

# Create the prompt template
prompt_template = PromptTemplate.from_template(NATURAL_TEMPLATE)

# Simple LCEL chain - no complex context filtering needed
qa_chain = (
        {
            "profile": lambda x: JAVIERA_PROFILE,
            "question": RunnablePassthrough()
        }
        | prompt_template
        | llm
        | StrOutputParser()
)


def chatbot_response(question: str) -> str:
    """Process user question and return natural response."""
    try:
        # Check for privacy restrictions
        if check_privacy_restrictions(question):
            return ("I appreciate your interest, but I prefer to keep that information private and focus on "
                    "professional topics. Is there anything else about my background or experience you'd like to know?")

        # Process the question through the chain
        response = qa_chain.invoke(question)
        return response.strip()

    except Exception as e:
        return "Sorry, I had a bit of a technical hiccup there! Could you try asking that again?"


def create_gradio_interface():
        examples = [
            "Tell me about yourself",
            "What's your background?",
            "How did you get into tech?",
            "Where have you lived?",
            "What programming languages do you know?",
            "What kind of work environment do you thrive in?",
            "What's your experience with data analytics?",
            "Why do you like living in Germany?",
            "Tell me about your interests and hobbies"
        ]

        with gr.Blocks(theme=gr.themes.Soft()) as app:
            gr.Markdown(
                """
                # üëã Chat with Javiera  
                I'm Javiera! I'm happy to chat about my professional journey, my international experiences, 
                and what I'm looking for in my next role. Ask me anything!  


                ‚ö†Ô∏è **Note:** My answers are generated by an AI and may not always be 100% accurate. Please verify any important information.
                """
            )

            with gr.Row():
                with gr.Column(scale=3):
                    chatbot = gr.Chatbot(label="Chat",type="messages")
                    msg = gr.Textbox(
                        label="Your Question",
                        placeholder="Hi! Ask me anything about my background, experience, or journey...",
                        lines=2
                    )
                    with gr.Row():
                        send = gr.Button("Send", variant="primary")  # purple
                        clear = gr.Button("Clear Chat", variant="secondary")  # gray

                with gr.Column(scale=1):
                    gr.Markdown("### Example Questions")
                    example_buttons = []
                    for ex in examples:
                        btn = gr.Button(ex)
                        example_buttons.append(btn)

            def respond(message, history):
                response = chatbot_response(message)
                history = history + [
                    {"role": "user", "content": message},
                    {"role": "assistant", "content": response}
                ]
                return history, ""

            msg.submit(respond, [msg, chatbot], [chatbot, msg])
            send.click(respond, [msg, chatbot], [chatbot, msg])
            clear.click(lambda: None, None, chatbot)

            # Make example buttons submit the message
            for btn in example_buttons:
                btn.click(respond, [btn, chatbot], [chatbot, msg])

        return app


# Launch the application
if __name__ == "__main__":
    app = create_gradio_interface()
    app.launch(
        share=False,  # Set to True if you want a public link
        show_error=True
    )
